---
title: "Exercise 2"
author: ""
date: "`r Sys.Date()`"
output:
  md_document
 
---
<!--   pdf_document: default
 md_document -->

```{r, include=FALSE}
options(tinytex.verbose = TRUE)
options(dplyr.summarise.inform = FALSE)
```

```{r setup, include=FALSE}
library(magrittr) # needs to be run every time you start R and want to use %>%
library(dplyr)    # alternatively, this also loads %>%
library(knitr)
library(tidyverse) 
library(sjmisc)
library(ggplot2)
library(reshape2)
library(gapminder)
library(mosaic)
library(extraDistr)
library(caret)
library(modelr)
library(parallel)
library(foreach)
library(rsample)
library(lubridate)
library(olsrr)
load("data.RData")
```

# 1) Saratoga house prices

## Pricing Strategy

### Main Focus: More preciously prediction for price
For the tax manager who want to know the precious prediction for price, we made more precious model from the data and suggested the points what elemets affect on how much price is. 

### Data
The description of the dataset in the salatago house;

<Independent variable>
- price: price (1000s of US dollars)

<Dependent variables(numerical)>
- lotSize: size of lot (square feet)
- Age: age of house (years)
- landValue: value of land (1000s of US dollars)
- livingArea: living are (square feet)
- pctCollege: percent of neighborhood that graduated college
- bedrooms: number of bedrooms
- fireplaces: number of fireplaces
- bathrooms: number of bathrooms (half bathrooms have no shower or tub)
- rooms: number of rooms

<Dependent variables(non-numerical)>
- heating: type of heating system
- fuel: fuel used for heating
- sewer: type of sewer system
- waterfront: whether property includes waterfront
- newConstruction: whether the property is a new construction
- centralAir: whether the house has central air

Documentation of the Saratago House dataset
https://r-data.pmagunia.com/dataset/r-dataset-package-mosaicdata-saratogahouses

### Model
We used the following steps to make the precious model.

- 1 Split data train/test dataset
- 2 Create squared variables and interaction variables of the numerical data in the SaratogaHouses

<Repeat start>
we repeated the followign procedures ten times and take an average of rmse

The estimation of the model is
$$
\begin{aligned}
log(Price) &= \beta_0+\mathbb{\beta_1}[numerical\ variables]^2+\mathbb{\beta_2}[interaction\ terms\ by\ each\ numerical\ variables]\\
&\quad +\mathbb{\beta_3}[non-numerical\ variables(dummy temrs)]
\end{aligned}
$$


- 3 Linear regression with all variables
- 4 Knn regression with all variables
<up to this>

- 5 Compared the average of rmse of Linear and Knn model to find better fit model
- 6 Summarized the better model and interpreted its meaning


### Results

```{r , eval=FALSE,echo=FALSE,fig.width =5.5, fig.height = 2,fig.align='center'}
# Setup
data(SaratogaHouses)

Lmrmse =NULL
Knnrmse =NULL

# Function: Create polym2
## Input: Dataset
## Output: New Dataset
## Create polynominal term by each column
## Example: dataframe(column 1*column1, column 1*column 2, .... column i*column j,....)
  all_polym2 <- function (dataset){
      result <- dataset
        for (i in 1:ncol(dataset)){
          for (j in i:ncol(dataset)){
            if(j==i){
              tmp = as.data.frame(dataset[,j]^2)
              colnames(tmp) <- paste(colnames(dataset[j]),"sq")
            }else
            {
              tmp = as.data.frame(dataset[,i] * dataset[,j])
              colnames(tmp) <- paste(colnames(dataset[i]),"_",colnames(dataset[j]))
            }
            result <- as.data.frame(c(result,tmp))
          }
        }
      return(result)
    }

# basemodel = lm(log(price)~ .,saratoga_train)
# step_model <- step(basemodel, scope=~(.)^2)
# rmse(step_model,saratoga_test)
# coef(step_model)
  
# Estimation
for (i in 1:10){
  ## Split into training and testing sets
  saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
  saratoga_train = training(saratoga_split)
  saratoga_test = testing(saratoga_split)
  
  data_train <- as.data.frame(c(saratoga_train[1],all_polym2(saratoga_train[2:10]),saratoga_train[11:16]))
  data_test <- as.data.frame(c(saratoga_test[1],all_polym2(saratoga_test[2:10]),saratoga_test[11:16]))

  ## Regression the linear model with all variables
  ## (because the more variables you will add to the model, the lower rmse you can get)
  model1 = lm(log(price)~ ., data=data_train)
  Lmrmse[i] = rmse(model1,data_test)


  ## Regression the Knn model with all variables
  ### now rescale for KNN with variables else dummies
  X_train <- saratoga_train[,2:10]
  X_test <- saratoga_test[,2:10]
  
  scale_train = apply(X_train, 2, sd) # calculate std dev for each column
  Xtilde_train = scale(X_train, scale = scale_train) %>% as.data.frame
  Xtilde_test = scale(X_test, scale = scale_train) %>% as.data.frame # use the training set scales!
  
  Xtilde_train = as.data.frame(cbind(Xtilde_train, saratoga_train['price'],saratoga_train[,11:16]))
  Xtilde_test = as.data.frame(cbind(Xtilde_test, saratoga_test['price'],saratoga_test[,11:16]))
    
  maxK=200
  ## KNN
    knnrmse = foreach(K = 2:maxK, .combine='rbind') %do% {
    knn = knnreg(log(price) ~ ., data=Xtilde_train, k=K)
    c(k=K,rmse=modelr::rmse(knn,Xtilde_test))
    }%>% as.data.frame
    
    Knnrmse = as.data.frame(cbind(Knnrmse, knnrmse$rmse))
  }

## Compared the result of the linear and knn( knn' rmse selected by the minimum of rmse)
result_lm = mean(Lmrmse, 1, mean, na.rm=TRUE)
result_knn = as.data.frame(apply(Knnrmse[,1:10], 1, mean, na.rm=TRUE))
result_knn =result_knn[result_knn ==min(result_knn ),]
result = c(result_lm,result_knn)
#summary(model1)
```

The liner model of RMSE is 0.2822 and The Knn model of RMSE is 0.3061. Please see the detail of the linear reagression in the appendix.

### Discussion: Comparison between Linear and LNN model
In this estimation, from the result that rmse of the linear model is smaller than that of knn model, the fitting of the linear model is better than that of the best linear model. We can think this reason is what the liner model that is set up  close to the true model.

## Conclusion for Tax authority

From the result of the estimation of the linear model(Appendix 1), we can say that elements that increases house prices are more "fireplaces", more "newConstructionNo" at the statistically siginificance. However, more "age", "heatinghot water/steam", "waterfrontNo" make its price decrease at the statistically siginificance.


## Appendix

### 1. Result of the model
```
Call:
lm(formula = log(price) ~ ., data = data_train)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.7497 -0.1405  0.0100  0.1576  1.1371 

Coefficients:
                          Estimate Std. Error t value Pr(>|t|)    
(Intercept)              1.149e+01  2.594e-01  44.320  < 2e-16 ***
lotSize                  1.400e-01  9.121e-02   1.535 0.125100    
age                     -6.528e-03  1.985e-03  -3.288 0.001037 ** 
landValue                2.991e-06  2.378e-06   1.258 0.208710    
livingArea               1.373e-04  1.658e-04   0.828 0.407822    
pctCollege              -2.385e-03  6.711e-03  -0.355 0.722334    
bedrooms                 1.206e-01  9.930e-02   1.215 0.224662    
fireplaces               4.066e-01  1.081e-01   3.761 0.000176 ***
bathrooms                2.879e-01  1.326e-01   2.171 0.030119 *  
rooms                    1.462e-02  3.464e-02   0.422 0.673072    
lotSize.sq               1.467e-03  4.970e-03   0.295 0.767818    
lotSize._.age           -1.063e-03  4.809e-04  -2.211 0.027197 *  
lotSize._.landValue     -7.900e-07  4.299e-07  -1.838 0.066306 .  
lotSize._.livingArea    -2.544e-05  4.040e-05  -0.630 0.528950    
lotSize._.pctCollege     8.655e-04  1.488e-03   0.582 0.560879    
lotSize._.bedrooms       1.467e-02  2.213e-02   0.663 0.507411    
lotSize._.fireplaces    -8.360e-03  3.149e-02  -0.265 0.790681    
lotSize._.bathrooms     -5.440e-02  3.014e-02  -1.805 0.071331 .  
lotSize._.rooms          5.359e-03  9.768e-03   0.549 0.583339    
age.sq                   1.744e-05  5.910e-06   2.951 0.003222 ** 
age._.landValue          1.959e-08  7.786e-09   2.516 0.011983 *  
age._.livingArea        -4.245e-07  8.106e-07  -0.524 0.600590    
age._.pctCollege         7.604e-05  2.970e-05   2.560 0.010585 *  
age._.bedrooms          -1.111e-04  4.943e-04  -0.225 0.822186    
age._.fireplaces         3.312e-04  6.099e-04   0.543 0.587238    
age._.bathrooms          7.385e-04  6.041e-04   1.222 0.221757    
age._.rooms             -2.342e-04  1.869e-04  -1.253 0.210419    
landValue.sq            -9.147e-12  2.599e-12  -3.520 0.000447 ***
landValue._.livingArea  -9.431e-10  7.145e-10  -1.320 0.187081    
landValue._.pctCollege   9.317e-08  3.619e-08   2.575 0.010144 *  
landValue._.bedrooms    -7.029e-07  4.219e-07  -1.666 0.095931 .  
landValue._.fireplaces  -1.186e-06  5.235e-07  -2.267 0.023574 *  
landValue._.bathrooms    7.389e-07  5.630e-07   1.312 0.189637    
landValue._.rooms        2.372e-08  1.764e-07   0.134 0.893069    
livingArea.sq           -3.616e-08  5.054e-08  -0.715 0.474500    
livingArea._.pctCollege  3.326e-06  2.451e-06   1.357 0.174924    
livingArea._.bedrooms    3.422e-05  4.263e-05   0.803 0.422323    
livingArea._.fireplaces -1.989e-05  5.200e-05  -0.382 0.702190    
livingArea._.bathrooms   9.046e-05  5.673e-05   1.595 0.111041    
livingArea._.rooms      -1.321e-05  2.035e-05  -0.649 0.516440    
pctCollege.sq           -4.168e-05  6.088e-05  -0.685 0.493686    
pctCollege._.bedrooms    3.026e-04  1.391e-03   0.218 0.827838    
pctCollege._.fireplaces -4.274e-03  1.552e-03  -2.754 0.005966 ** 
pctCollege._.bathrooms  -1.383e-03  1.852e-03  -0.747 0.455277    
pctCollege._.rooms      -2.517e-05  5.227e-04  -0.048 0.961603    
bedrooms.sq             -3.858e-03  1.592e-02  -0.242 0.808578    
bedrooms._.fireplaces   -5.325e-02  2.805e-02  -1.899 0.057841 .  
bedrooms._.bathrooms    -6.534e-02  3.109e-02  -2.102 0.035765 *  
bedrooms._.rooms        -1.430e-04  1.105e-02  -0.013 0.989677    
fireplaces.sq            2.558e-02  2.486e-02   1.029 0.303794    
fireplaces._.bathrooms   7.453e-03  3.599e-02   0.207 0.835996    
fireplaces._.rooms       6.778e-03  1.080e-02   0.628 0.530341    
bathrooms.sq            -3.959e-02  2.735e-02  -1.448 0.147982    
bathrooms._.rooms        9.407e-03  1.204e-02   0.781 0.434895    
rooms.sq                 2.086e-04  3.692e-03   0.057 0.954952    
heatinghot water/steam  -4.657e-02  2.266e-02  -2.055 0.040033 *  
heatingelectric          3.426e-02  6.399e-02   0.535 0.592505    
fuelelectric            -5.308e-02  6.323e-02  -0.839 0.401376    
fueloil                 -7.454e-03  2.733e-02  -0.273 0.785087    
sewerpublic/commercial   1.201e-02  2.076e-02   0.579 0.562873    
sewernone               -1.179e-01  8.472e-02  -1.392 0.164108    
waterfrontNo            -5.851e-01  8.477e-02  -6.903  7.9e-12 ***
newConstructionNo        1.391e-01  4.102e-02   3.390 0.000719 ***
centralAirNo            -1.832e-02  1.831e-02  -1.000 0.317270    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.2678 on 1318 degrees of freedom
Multiple R-squared:  0.645,	Adjusted R-squared:  0.6281 
F-statistic: 38.02 on 63 and 1318 DF,  p-value: < 2.2e-16

```

\newpage

# 2) Classification and retrospective sampling

## Results
```{r ,  eval=FALSE,include=FALSE}
german_credit <- read.csv('german_credit.csv')
gc_split = initial_split(german_credit, prop = 0.8)
gc_train = training(gc_split)
gc_test = testing(gc_split)

logit_gc <- glm(Default ~ duration + amount + installment + age + history + purpose + foreign, data = gc_train, family=binomial)
coef(logit_gc) %>% round(2)

phat_test_logit_gc = predict(logit_gc, gc_test, type='response')
yhat_test_logit_gc = ifelse(phat_test_logit_gc > 0.5, 1, 0)
confusion_out_logit = table(y = gc_test$Default, yhat = yhat_test_logit_gc)
#confusion_out_logit
#sum(diag(confusion_out_logit))/sum(confusion_out_logit) # out-of-sample accuracy
#table(gc_test$Default)
```



```
The coefficients of the logit model
        (Intercept)            duration              amount         installment                 age         historypoor 
              -0.66                0.02                0.00                0.19               -0.02               -1.30 
    historyterrible          purposeedu purposegoods/repair       purposenewcar      purposeusedcar       foreigngerman 
              -2.02                0.91                0.13                0.94               -0.67               -1.55 

confusion matrix
   yhat
y     0   1
  0 131  11
  1  44  14

out-of-sample accuracy rate
0.725

the result of the null model
  0   1 
142  58 

the null model accuracy rate
0.71
```

## Disucussion 

### What do you notice about the history variable vis-a-vis predicting defaults?

From the coefficient of the logit model, the poor and terrible of the history made the probability of default decrease.

### What do you think is going on here?

Intuitively, the poor and terrible of the history made the probability of default increase. So there is something with the bad estimation. We can think this reason is caused by what the default is rare, and so we cannot collect data randomly(the data is not collected through random sampling) that is biased.

### Do you think this data set is appropriate for building a predictive model of defaults

We don't think so. Because the out-of-sample accuracy rate is 0.725 while the null model accuracy rate is 0.71. Therefore, the improvement of the estimation is so low.

### Would you recommend any changes to the bank's sampling scheme?

As we said above, the data should be collected randomly that will make biased decrease.

\newpage

# 3) Children and hotel reservations

## Model Building
```{r , eval=FALSE,include=FALSE}
hotels_dev <- read.csv('hotels_dev.csv')

hotels_dev_split = initial_split(hotels_dev, prop = 0.8)
hotels_dev_train= training(hotels_dev_split)
hotels_dev_test = testing(hotels_dev_split)

# Models
baseline1 <- glm(children~market_segment+adults+customer_type+is_repeated_guest,data=hotels_dev_train, family=binomial)
baseline2 <- glm(children~.-arrival_date,data=hotels_dev_train, family=binomial)

model <- glm(children~.-arrival_date+year(arrival_date)+month(arrival_date)+average_daily_rate:adults+days_in_waiting_list:adults+ stays_in_weekend_nights :adults+total_of_special_requests:adults+booking_changes:average_daily_rate+booking_changes:days_in_waiting_list+lead_time:booking_changes+lead_time^2,data=hotels_dev_train)

## (*)Other glms
## if add arrival year/month/date to the base line 2, the correction of the prediction is larger than that of the baseline 2
## And, I add three polynominal parameters()
## Caluculation of the variation "apply(hotels_dev_train, 2, sd)"
     #                     hotel                      lead_time        stays_in_weekend_nights           stays_in_weekend_nights  
     #                        NA                     91.1969864                      0.9870792                      1.9086186 
     #                    adults                       children                           meal                 market_segment 
     #                 0.5086470                      0.2743685                             NA                             NA 
     #      distribution_channel              is_repeated_guest         previous_cancellations previous_bookings_not_canceled 
     #                        NA                      0.2036092                      0.2917516                      1.7965860 
     #        reserved_room_type             assigned_room_type                booking_changes                   deposit_type 
     #                        NA                             NA                      0.7316105                             NA 
     #      days_in_waiting_list                  customer_type             average_daily_rate    required_car_parking_spaces 
     #                14.7206015                             NA                     48.7072715                             NA 
     # total_of_special_requests                   arrival_date 
     #                 0.8352343                             NA 


## (**)Others attempts--- But the correction of the prediction is lower than that of the baseline 2
## glmstep_b1 <- step(baseline1, scope=~(.)^2)
## 
## glm0 = glm(children ~ 1, data=hotels_dev_train, family=binomial)
## glm_forward = step(glm0, direction='forward',
## scope=~(market_segment+adults+customer_type+is_repeated_guest)^2)
##
##lm0 = lm(children ~ 1, data=hotels_dev_train)
##lm_forward0 = step(lm0, direction='forward',
##scope=~(market_segment+adults+customer_type+is_repeated_guest)^2)


# predict and rmse
predict1 <- predict(baseline1, newdata=hotels_dev_test, type='response')
predict2 <- predict(baseline2, newdata=hotels_dev_test, type='response')
predict3 <- predict(model, newdata=hotels_dev_test, type='response')
##predict4 <- predict(glm_forward, newdata=hotels_dev_test, type='response')
##predict5 <- predict(lm_forward, newdata=hotels_dev_test, type='response')
##predict6 <- predict(glmstep_b1, newdata=hotels_dev_test, type='response')


# predict
yhat_test1 = ifelse(predict1 > 0.5, 1, 0)
yhat_test2 = ifelse(predict2 > 0.5, 1, 0)
yhat_test3 = ifelse(predict3 > 0.5, 1, 0)
##yhat_test4 = ifelse(predict4 > 0.5, 1, 0)
##yhat_test5 = ifelse(predict5 > 0.5, 1, 0)
##yhat_test6 = ifelse(predict6 > 0.5, 1, 0)

confusion_out1= table(y = hotels_dev_test$children, yhat = yhat_test1)
confusion_out2= table(y = hotels_dev_test$children, yhat = yhat_test2)
confusion_out3= table(y = hotels_dev_test$children, yhat = yhat_test3)
##confusion_out4= table(y = hotels_dev_test$children, yhat = yhat_test4)
##confusion_out5= table(y = hotels_dev_test$children, yhat = yhat_test5)
##confusion_out6= table(y = hotels_dev_test$children, yhat = yhat_test6)

result1 = sum(diag(confusion_out1))/sum(confusion_out1)
result2 = sum(diag(confusion_out2))/sum(confusion_out2)
result3 = sum(diag(confusion_out3))/sum(confusion_out3)
##result4 = sum(diag(confusion_out4))/sum(confusion_out4)
##result5 = sum(diag(confusion_out5))/sum(confusion_out5)
##result6 = sum(diag(confusion_out6))/sum(confusion_out6)

save.image("data.RData")
```

### Models

We shows the models that we used in this problems. First, the baseline 1 is
$$
\begin{aligned}
children = \beta_0+\boldsymbol \beta \mathbf{X}_{market\ segment,  \ adults,\ customer_type,\ is\ repeated\ guest}
\end{aligned}
$$

The baseline 2 is
$$
\begin{aligned}
children = \beta_0+\boldsymbol \beta \mathbf{X}_{all\ variables\ excpet\ arriving\ date}
\end{aligned}
$$

The our model is
$$
\begin{aligned}
children &= \beta_0+\boldsymbol \beta \mathbf{X}_{all\ variables\ excpet\ arriving\ date}+arriving\ year+ arriving\ month \\
& \quad +average\ daily\ rate\times adults \\
& \quad +\ days\ in\ waiting_list\times adults\\
&\quad + stays\ in\ weekend_nights\times adults\\
&\quad +total\ of\ special\ requests\times adults \\
&\quad +booking\ changes\times average\ daily\ rate\\
&\quad +booking\ changes\times days\ in\ waiting_list \\
&\quad +lead\ time \times booking\ changes \\
&\quad +(lead\ time)^2
\end{aligned}
$$

### Check

Out-of-sample accuracy rate by each model is
```{r, echo=FALSE}
knitr::kable(cbind(baseline1=result1,baseline2= result2,mymodel=result3))
```

Therefore, the model accuracy of my model is higher than the baseline2 by 0.1% and thn the baseline 1 by 1.7%. 

## Model validation: step 1

```{r , eval=FALSE,include=FALSE}
# Model Valuation: Step1
hotels_val <- read.csv('hotels_val.csv')

hotels_val_split = initial_split(hotels_val, prop = 0.8)
hotels_val_train= training(hotels_val_split)
hotels_val_test = testing(hotels_val_split)

baseline1 <- glm(children~market_segment+adults+customer_type+is_repeated_guest,data=hotels_val_train, family=binomial)
baseline2 <- glm(children~.-arrival_date,data=hotels_dev_train, family=binomial)

## I COULD NOT UNDERSTAND: glm(children~.-arrival_date,data=hotels_dev_train, family=binomial)
## The simple and same regression does not work =glm(children~.-arrival_date,data=hotels_dev_train, family=binomial)
model_val <- glm(children~hotel+lead_time+stays_in_weekend_nights+stays_in_week_nights+adults+children+meal+market_segment+distribution_channel+is_repeated_guest+previous_cancellations+previous_bookings_not_canceled+reserved_room_type+assigned_room_type+booking_changes+deposit_type+days_in_waiting_list+customer_type+average_daily_rate+required_car_parking_spaces+total_of_special_requests+year(arrival_date)+month(arrival_date)+average_daily_rate:adults+days_in_waiting_list:adults+ stays_in_weekend_nights :adults+total_of_special_requests:adults+booking_changes:average_daily_rate+booking_changes:days_in_waiting_list+lead_time:booking_changes+lead_time^2,data=hotels_val_train, family=binomial)

predict_baselin1_val <- predict(baseline1, newdata=hotels_val_test, type='response')
predict_baselin2_val <- predict(baseline2, newdata=hotels_val_test, type='response')
predict_model_val <- predict(model_val, newdata=hotels_val_test, type='response')


## IF t=0.5
## yhat_test_val = ifelse(predict_val > 0.5, 1, 0)
## confusion_out_val= table(y = hotels_val_test$children, yhat = yhat_test_val)
## tpr = confusion_out_val[2,2]/sum(confusion_out_val[2,])
## fpr = confusion_out_val[1,2]/sum(confusion_out_val[1,])

## IF t= 0.05-0.95
## Since I could get some errors if t= 0-1, I set up like above but it looks like that does not matter with the overall results.
result_step1 <- foreach(t= seq(0.1,0.9,0.01), .combine=rbind) %do%{
  #yhat_base1_val = ifelse(predict_baselin1_val > t, 1, 0)
  yhat_base2_val = ifelse(predict_baselin2_val > t, 1, 0)  
  yhat_model_val = ifelse(predict_model_val > t, 1, 0)
  
  #confusion_base1_val= table(y = hotels_val_test$children, yhat = yhat_base1_val)
  confusion_base2_val= table(y = hotels_val_test$children, yhat = yhat_base2_val)
  confusion_model_val= table(y = hotels_val_test$children, yhat = yhat_model_val)

  #tpr_base1 = confusion_base1_val[2,2]/sum(confusion_model_val[2,])
  #fpr_base1 = confusion_base1_val[1,2]/sum(confusion_base1_val[1,])
  tpr_base2 = confusion_base2_val[2,2]/sum(confusion_base2_val[2,])
  fpr_base2 = confusion_base2_val[1,2]/sum(confusion_base2_val[1,])
  tpr_model = confusion_model_val[2,2]/sum(confusion_model_val[2,])
  fpr_model = confusion_model_val[1,2]/sum(confusion_model_val[1,])
  c(t=t,tpr_base2=tpr_base2,fpr_base2=fpr_base2,tpr_model=tpr_model,fpr_model=fpr_model)
} %>% as.data.frame

## Plot ROC curve
ggplot(data =result_step1)+ geom_line(aes(x=fpr_base2, y=tpr_base2),colour="red")+ geom_line(aes(x=fpr_model, y=tpr_model),color="blue")
ggsave("./graph/result_step1.png")
```

The ROC curve of baseline 2 and my model is

```{r, echo=FALSE,out.width ="70%", out.height = "70%",fig.align='center'}
# Show the above result as a table
knitr::include_graphics("./graph/result_step1.png")
```

red line: baseline 2, blue line: my model

From the graph, if FPR=0.05 my model has higher tpr than baseline 2, and so my model is better than baseline 2 in this case. 

However, in the low FPR, the TPR of baseline 2 is higher than that of my model, and so my model is worse than baseline 2. Also, in the high FPR, the TPR of baseline 2 is lower than that of my model, and so my model is better than baseline 2.


### Model validation: step 2

```{r , eval=FALSE,include=FALSE}
# Create Folds
hotels_val2 = crossv_kfold(hotels_val, k=20)

result_step2 = foreach(i = 1:20, .combine='rbind') %do% {
  # Model
  base_val2 <- glm(children~hotel+lead_time+stays_in_weekend_nights+stays_in_week_nights+adults+children+meal+market_segment+distribution_channel+is_repeated_guest+previous_cancellations+previous_bookings_not_canceled+reserved_room_type+assigned_room_type+booking_changes+deposit_type+days_in_waiting_list+customer_type+average_daily_rate+required_car_parking_spaces+total_of_special_requests,data=hotels_val2$train[[i]], family=binomial)
  model_val2 <- glm(children~.-arrival_date+year(arrival_date)+month(arrival_date)+average_daily_rate:adults+days_in_waiting_list:adults+ stays_in_weekend_nights :adults+total_of_special_requests:adults+booking_changes:average_daily_rate+booking_changes:days_in_waiting_list+lead_time:booking_changes+lead_time^2,data=hotels_val2$train[[i]], family=binomial)
  #Predict
  predict_base2 <- predict(base_val2 , newdata=hotels_val2$test[[i]], type='response')
  predict_val <- predict(model_val, newdata=hotels_val2$test[[i]], type='response')
  
  yhat_base2_val = ifelse(predict_base2 > 0.5, 1, 0)
  yhat_model_val = ifelse(predict_val > 0.5, 1, 0)

  confusion_base2_val= table(y = as.data.frame(hotels_val2$test[[i]])$children, yhat = yhat_base2_val)
  confusion_model_val= table(y = as.data.frame(hotels_val2$test[[i]])$children, yhat = yhat_model_val)
  # Estimation and Actual
  c(predict_base2 =sum(confusion_base2_val[,2]) , predict_model =  sum(confusion_model_val[,2]),actual=sum(confusion_model_val[2,]))
 } %>% as.data.frame
rownames(result_step2) <- c(1:20)

# Show the result on the Console
sum(result_step2$predict_base2)
sum(result_step2$predict_model)
sum(result_step2$actual)
save.image("data.RData")
```

In this case, we assumed a threshold is 50%, and our results is in the following. 
```{r, echo=FALSE,out.width ="70%", out.height = "70%",fig.align='center'}
# Show the above result as a table
knitr::kable(result_step2)
knitr::kable(cbind(sum_base2=sum(result_step2$predict_base2), sum_predict=sum(result_step2$predict_model), sum_actual=sum(result_step2$actual)))
```

From the result, the predicting the total number of bookings with children by baseline 2 is 207, that by my model is 221, and that by actual data is 402. The accurancy of the prediction of the our model is around 50%, which is so lower than we expected. However, our model's accurancy of the prediction is higher than the baseline 2's one.
