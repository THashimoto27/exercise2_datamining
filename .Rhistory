#Here lm1 is the medium model as per the lecture notes (taught in class).
lm1 = lm(price ~. -pctCollege -swere -waterfront -landaValue-newConstruction, data=saratoga_train)
lm2 = lm(price ~ lotSize^2 + age^2 + landValue^2 + livingArea^2 + pctCollege^2 + bedrooms^2 + fireplaces^2 + bathrooms^2 + rooms^2 + lotSize:age + landValue:age + livingArea:age + bedrooms:age, data=saratoga_train)
lm3 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:lotSize + landValue:lotSize + livingArea:lotSize + bedrooms:lotSize, data=saratoga_train)
lm4 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:bathrooms + landValue:bathrooms + livingArea:bathrooms + bedrooms:bathrooms, data=saratoga_train)
lm5 = lm(price ~ (. - heating - sewer - waterfront - newConstruction)^2, data=saratoga_train)
## Regression the linear model with all variables
## (because the more variables you will add to the model, the lower rmse you can get)
lm6 = lm(price~ ., data=data_train)
r1[i] = rmse(lm1, saratoga_test)
r2[i] = rmse(lm2, saratoga_test)
r3[i] = rmse(lm3, saratoga_test)
r4[i] = rmse(lm4, saratoga_test)
r5[i] = rmse(lm5, saratoga_test)
r6[i] = rmse(lm6,data_test)
## Regression the Knn model with all variables
### now rescale for KNN with variables else dummies
X_train <- saratoga_train[,2:10]
X_test <- saratoga_test[,2:10]
scale_train = apply(X_train, 2, sd) # calculate std dev for each column
Xtilde_train = scale(X_train, scale = scale_train) %>% as.data.frame
Xtilde_test = scale(X_test, scale = scale_train) %>% as.data.frame # use the training set scales!
Xtilde_train = as.data.frame(cbind(Xtilde_train, saratoga_train['price'],saratoga_train[,11:16]))
Xtilde_test = as.data.frame(cbind(Xtilde_test, saratoga_test['price'],saratoga_test[,11:16]))
maxK=200
## KNN
knnrmse = foreach(K = 2:maxK, .combine='rbind') %do% {
knn = knnreg(price ~ ., data=Xtilde_train, k=K)
c(k=K,rmse=modelr::rmse(knn,Xtilde_test))
}%>% as.data.frame
Knnrmse = as.data.frame(cbind(Knnrmse, knnrmse$rmse))
}
# Setup
data(SaratogaHouses)
Lmrmse =NULL
Knnrmse =NULL
r1= NULL
r2=NULL
r3=NULL
r4 = NULL
r5=NULL
r6=NULL
# Function: Create polym2
## Input: Dataset
## Output: New Dataset
## Create polynominal term by each column
## Example: dataframe(column 1*column1, column 1*column 2, .... column i*column j,....)
all_polym2 <- function (dataset){
result <- dataset
for (i in 1:ncol(dataset)){
for (j in i:ncol(dataset)){
if(j==i){
tmp = as.data.frame(dataset[,j]^2)
colnames(tmp) <- paste(colnames(dataset[j]),"sq")
}else
{
tmp = as.data.frame(dataset[,i] * dataset[,j])
colnames(tmp) <- paste(colnames(dataset[i]),"_",colnames(dataset[j]))
}
result <- as.data.frame(c(result,tmp))
}
}
return(result)
}
# Estimation
for (i in 1:10){
## Split into training and testing sets
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)
data_train <- as.data.frame(c(saratoga_train[1],all_polym2(saratoga_train[2:10]),saratoga_train[11:16]))
data_test <- as.data.frame(c(saratoga_test[1],all_polym2(saratoga_test[2:10]),saratoga_test[11:16]))
#Here lm1 is the medium model as per the lecture notes (taught in class).
lm1 = lm(price ~. -pctCollege -swer -waterfront -landaValue-newConstruction, data=saratoga_train)
lm2 = lm(price ~ lotSize^2 + age^2 + landValue^2 + livingArea^2 + pctCollege^2 + bedrooms^2 + fireplaces^2 + bathrooms^2 + rooms^2 + lotSize:age + landValue:age + livingArea:age + bedrooms:age, data=saratoga_train)
lm3 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:lotSize + landValue:lotSize + livingArea:lotSize + bedrooms:lotSize, data=saratoga_train)
lm4 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:bathrooms + landValue:bathrooms + livingArea:bathrooms + bedrooms:bathrooms, data=saratoga_train)
lm5 = lm(price ~ (. - heating - sewer - waterfront - newConstruction)^2, data=saratoga_train)
## Regression the linear model with all variables
## (because the more variables you will add to the model, the lower rmse you can get)
lm6 = lm(price~ ., data=data_train)
r1[i] = rmse(lm1, saratoga_test)
r2[i] = rmse(lm2, saratoga_test)
r3[i] = rmse(lm3, saratoga_test)
r4[i] = rmse(lm4, saratoga_test)
r5[i] = rmse(lm5, saratoga_test)
r6[i] = rmse(lm6,data_test)
## Regression the Knn model with all variables
### now rescale for KNN with variables else dummies
X_train <- saratoga_train[,2:10]
X_test <- saratoga_test[,2:10]
scale_train = apply(X_train, 2, sd) # calculate std dev for each column
Xtilde_train = scale(X_train, scale = scale_train) %>% as.data.frame
Xtilde_test = scale(X_test, scale = scale_train) %>% as.data.frame # use the training set scales!
Xtilde_train = as.data.frame(cbind(Xtilde_train, saratoga_train['price'],saratoga_train[,11:16]))
Xtilde_test = as.data.frame(cbind(Xtilde_test, saratoga_test['price'],saratoga_test[,11:16]))
maxK=200
## KNN
knnrmse = foreach(K = 2:maxK, .combine='rbind') %do% {
knn = knnreg(price ~ ., data=Xtilde_train, k=K)
c(k=K,rmse=modelr::rmse(knn,Xtilde_test))
}%>% as.data.frame
Knnrmse = as.data.frame(cbind(Knnrmse, knnrmse$rmse))
}
# Setup
data(SaratogaHouses)
Lmrmse =NULL
Knnrmse =NULL
r1= NULL
r2=NULL
r3=NULL
r4 = NULL
r5=NULL
r6=NULL
# Function: Create polym2
## Input: Dataset
## Output: New Dataset
## Create polynominal term by each column
## Example: dataframe(column 1*column1, column 1*column 2, .... column i*column j,....)
all_polym2 <- function (dataset){
result <- dataset
for (i in 1:ncol(dataset)){
for (j in i:ncol(dataset)){
if(j==i){
tmp = as.data.frame(dataset[,j]^2)
colnames(tmp) <- paste(colnames(dataset[j]),"sq")
}else
{
tmp = as.data.frame(dataset[,i] * dataset[,j])
colnames(tmp) <- paste(colnames(dataset[i]),"_",colnames(dataset[j]))
}
result <- as.data.frame(c(result,tmp))
}
}
return(result)
}
# Estimation
for (i in 1:10){
## Split into training and testing sets
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)
data_train <- as.data.frame(c(saratoga_train[1],all_polym2(saratoga_train[2:10]),saratoga_train[11:16]))
data_test <- as.data.frame(c(saratoga_test[1],all_polym2(saratoga_test[2:10]),saratoga_test[11:16]))
#Here lm1 is the medium model as per the lecture notes (taught in class).
lm1 = lm(price ~. -pctCollege -sewer -waterfront -landaValue-newConstruction, data=saratoga_train)
lm2 = lm(price ~ lotSize^2 + age^2 + landValue^2 + livingArea^2 + pctCollege^2 + bedrooms^2 + fireplaces^2 + bathrooms^2 + rooms^2 + lotSize:age + landValue:age + livingArea:age + bedrooms:age, data=saratoga_train)
lm3 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:lotSize + landValue:lotSize + livingArea:lotSize + bedrooms:lotSize, data=saratoga_train)
lm4 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:bathrooms + landValue:bathrooms + livingArea:bathrooms + bedrooms:bathrooms, data=saratoga_train)
lm5 = lm(price ~ (. - heating - sewer - waterfront - newConstruction)^2, data=saratoga_train)
## Regression the linear model with all variables
## (because the more variables you will add to the model, the lower rmse you can get)
lm6 = lm(price~ ., data=data_train)
r1[i] = rmse(lm1, saratoga_test)
r2[i] = rmse(lm2, saratoga_test)
r3[i] = rmse(lm3, saratoga_test)
r4[i] = rmse(lm4, saratoga_test)
r5[i] = rmse(lm5, saratoga_test)
r6[i] = rmse(lm6,data_test)
## Regression the Knn model with all variables
### now rescale for KNN with variables else dummies
X_train <- saratoga_train[,2:10]
X_test <- saratoga_test[,2:10]
scale_train = apply(X_train, 2, sd) # calculate std dev for each column
Xtilde_train = scale(X_train, scale = scale_train) %>% as.data.frame
Xtilde_test = scale(X_test, scale = scale_train) %>% as.data.frame # use the training set scales!
Xtilde_train = as.data.frame(cbind(Xtilde_train, saratoga_train['price'],saratoga_train[,11:16]))
Xtilde_test = as.data.frame(cbind(Xtilde_test, saratoga_test['price'],saratoga_test[,11:16]))
maxK=200
## KNN
knnrmse = foreach(K = 2:maxK, .combine='rbind') %do% {
knn = knnreg(price ~ ., data=Xtilde_train, k=K)
c(k=K,rmse=modelr::rmse(knn,Xtilde_test))
}%>% as.data.frame
Knnrmse = as.data.frame(cbind(Knnrmse, knnrmse$rmse))
}
# Setup
data(SaratogaHouses)
Lmrmse =NULL
Knnrmse =NULL
r1= NULL
r2=NULL
r3=NULL
r4 = NULL
r5=NULL
r6=NULL
# Function: Create polym2
## Input: Dataset
## Output: New Dataset
## Create polynominal term by each column
## Example: dataframe(column 1*column1, column 1*column 2, .... column i*column j,....)
all_polym2 <- function (dataset){
result <- dataset
for (i in 1:ncol(dataset)){
for (j in i:ncol(dataset)){
if(j==i){
tmp = as.data.frame(dataset[,j]^2)
colnames(tmp) <- paste(colnames(dataset[j]),"sq")
}else
{
tmp = as.data.frame(dataset[,i] * dataset[,j])
colnames(tmp) <- paste(colnames(dataset[i]),"_",colnames(dataset[j]))
}
result <- as.data.frame(c(result,tmp))
}
}
return(result)
}
# Estimation
for (i in 1:10){
## Split into training and testing sets
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)
data_train <- as.data.frame(c(saratoga_train[1],all_polym2(saratoga_train[2:10]),saratoga_train[11:16]))
data_test <- as.data.frame(c(saratoga_test[1],all_polym2(saratoga_test[2:10]),saratoga_test[11:16]))
#Here lm1 is the medium model as per the lecture notes (taught in class).
lm1 = lm(price ~. -pctCollege -sewer -waterfront -landValue-newConstruction, data=saratoga_train)
lm2 = lm(price ~ lotSize^2 + age^2 + landValue^2 + livingArea^2 + pctCollege^2 + bedrooms^2 + fireplaces^2 + bathrooms^2 + rooms^2 + lotSize:age + landValue:age + livingArea:age + bedrooms:age, data=saratoga_train)
lm3 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:lotSize + landValue:lotSize + livingArea:lotSize + bedrooms:lotSize, data=saratoga_train)
lm4 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:bathrooms + landValue:bathrooms + livingArea:bathrooms + bedrooms:bathrooms, data=saratoga_train)
lm5 = lm(price ~ (. - heating - sewer - waterfront - newConstruction)^2, data=saratoga_train)
## Regression the linear model with all variables
## (because the more variables you will add to the model, the lower rmse you can get)
lm6 = lm(price~ ., data=data_train)
r1[i] = rmse(lm1, saratoga_test)
r2[i] = rmse(lm2, saratoga_test)
r3[i] = rmse(lm3, saratoga_test)
r4[i] = rmse(lm4, saratoga_test)
r5[i] = rmse(lm5, saratoga_test)
r6[i] = rmse(lm6,data_test)
## Regression the Knn model with all variables
### now rescale for KNN with variables else dummies
X_train <- saratoga_train[,2:10]
X_test <- saratoga_test[,2:10]
scale_train = apply(X_train, 2, sd) # calculate std dev for each column
Xtilde_train = scale(X_train, scale = scale_train) %>% as.data.frame
Xtilde_test = scale(X_test, scale = scale_train) %>% as.data.frame # use the training set scales!
Xtilde_train = as.data.frame(cbind(Xtilde_train, saratoga_train['price'],saratoga_train[,11:16]))
Xtilde_test = as.data.frame(cbind(Xtilde_test, saratoga_test['price'],saratoga_test[,11:16]))
maxK=200
## KNN
knnrmse = foreach(K = 2:maxK, .combine='rbind') %do% {
knn = knnreg(price ~ ., data=Xtilde_train, k=K)
c(k=K,rmse=modelr::rmse(knn,Xtilde_test))
}%>% as.data.frame
Knnrmse = as.data.frame(cbind(Knnrmse, knnrmse$rmse))
}
## Compared the result of the linear and knn( knn' rmse selected by the minimum of rmse)
result_lm1 = mean(r1, 1, mean, na.rm=TRUE)
result_lm2 = mean(r2, 1, mean, na.rm=TRUE)
result_lm3 = mean(r3, 1, mean, na.rm=TRUE)
result_lm4 = mean(r4, 1, mean, na.rm=TRUE)
result_lm5 = mean(r5, 1, mean, na.rm=TRUE)
result_lm6 = mean(r6, 1, mean, na.rm=TRUE)
result_knn = as.data.frame(apply(Knnrmse[,1:10], 1, mean, na.rm=TRUE))
result_knn =result_knn[result_knn ==min(result_knn ),]
result = c(result_lm1,result_lm2,result_lm3,result_lm4,result_lm5,result_lm6,result_knn)
#summary(model1)
# Setup
data(SaratogaHouses)
Lmrmse =NULL
Knnrmse =NULL
r1= NULL
r2=NULL
r3=NULL
r4 = NULL
r5=NULL
r6=NULL
# Function: Create polym2
## Input: Dataset
## Output: New Dataset
## Create polynominal term by each column
## Example: dataframe(column 1*column1, column 1*column 2, .... column i*column j,....)
all_polym2 <- function (dataset){
result <- dataset
for (i in 1:ncol(dataset)){
for (j in i:ncol(dataset)){
if(j==i){
tmp = as.data.frame(dataset[,j]^2)
colnames(tmp) <- paste(colnames(dataset[j]),"sq")
}else
{
tmp = as.data.frame(dataset[,i] * dataset[,j])
colnames(tmp) <- paste(colnames(dataset[i]),"_",colnames(dataset[j]))
}
result <- as.data.frame(c(result,tmp))
}
}
return(result)
}
# Estimation
for (i in 1:10){
## Split into training and testing sets
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)
data_train <- as.data.frame(c(saratoga_train[1],all_polym2(saratoga_train[2:10]),saratoga_train[11:16]))
data_test <- as.data.frame(c(saratoga_test[1],all_polym2(saratoga_test[2:10]),saratoga_test[11:16]))
#Here lm1 is the medium model as per the lecture notes (taught in class).
lm1 = lm(price ~. -pctCollege -sewer -waterfront -landValue-newConstruction, data=saratoga_train)
lm2 = lm(price ~ lotSize^2 + age^2 + landValue^2 + livingArea^2 + pctCollege^2 + bedrooms^2 + fireplaces^2 + bathrooms^2 + rooms^2 + lotSize:age + landValue:age + livingArea:age + bedrooms:age, data=saratoga_train)
lm3 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:lotSize + landValue:lotSize + livingArea:lotSize + bedrooms:lotSize, data=saratoga_train)
lm4 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:bathrooms + landValue:bathrooms + livingArea:bathrooms + bedrooms:bathrooms, data=saratoga_train)
lm5 = lm(price ~ (. - heating - sewer - waterfront - newConstruction)^2, data=saratoga_train)
## Regression the linear model with all variables
## (because the more variables you will add to the model, the lower rmse you can get)
lm6 = lm(price~ ., data=data_train)
r1[i] = rmse(lm1, saratoga_test)
r2[i] = rmse(lm2, saratoga_test)
r3[i] = rmse(lm3, saratoga_test)
r4[i] = rmse(lm4, saratoga_test)
r5[i] = rmse(lm5, saratoga_test)
r6[i] = rmse(lm6,data_test)
## Regression the Knn model with all variables
### now rescale for KNN with variables else dummies
X_train <- saratoga_train[,2:10]
X_test <- saratoga_test[,2:10]
scale_train = apply(X_train, 2, sd) # calculate std dev for each column
Xtilde_train = scale(X_train, scale = scale_train) %>% as.data.frame
Xtilde_test = scale(X_test, scale = scale_train) %>% as.data.frame # use the training set scales!
Xtilde_train = as.data.frame(cbind(Xtilde_train, saratoga_train['price'],saratoga_train[,11:16]))
Xtilde_test = as.data.frame(cbind(Xtilde_test, saratoga_test['price'],saratoga_test[,11:16]))
maxK=200
## KNN
knnrmse = foreach(K = 2:maxK, .combine='rbind') %do% {
knn = knnreg(price ~ ., data=Xtilde_train, k=K)
c(k=K,rmse=modelr::rmse(knn,Xtilde_test))
}%>% as.data.frame
Knnrmse = as.data.frame(cbind(Knnrmse, knnrmse$rmse))
}
## Compared the result of the linear and knn( knn' rmse selected by the minimum of rmse)
result_lm1 = mean(r1, 1, mean, na.rm=TRUE)
result_lm2 = mean(r2, 1, mean, na.rm=TRUE)
result_lm3 = mean(r3, 1, mean, na.rm=TRUE)
result_lm4 = mean(r4, 1, mean, na.rm=TRUE)
result_lm5 = mean(r5, 1, mean, na.rm=TRUE)
result_lm6 = mean(r6, 1, mean, na.rm=TRUE)
result_knn = as.data.frame(apply(Knnrmse[,1:10], 1, mean, na.rm=TRUE))
result_knn =result_knn[result_knn ==min(result_knn ),]
result = c(result_lm1,result_lm2,result_lm3,result_lm4,result_lm5,result_lm6,result_knn)
#summary(model1)
# Setup
data(SaratogaHouses)
Lmrmse =NULL
Knnrmse =NULL
r1= NULL
r2=NULL
r3=NULL
r4 = NULL
r5=NULL
r6=NULL
# Function: Create polym2
## Input: Dataset
## Output: New Dataset
## Create polynominal term by each column
## Example: dataframe(column 1*column1, column 1*column 2, .... column i*column j,....)
all_polym2 <- function (dataset){
result <- dataset
for (i in 1:ncol(dataset)){
for (j in i:ncol(dataset)){
if(j==i){
tmp = as.data.frame(dataset[,j]^2)
colnames(tmp) <- paste(colnames(dataset[j]),"sq")
}else
{
tmp = as.data.frame(dataset[,i] * dataset[,j])
colnames(tmp) <- paste(colnames(dataset[i]),"_",colnames(dataset[j]))
}
result <- as.data.frame(c(result,tmp))
}
}
return(result)
}
# Estimation
for (i in 1:10){
## Split into training and testing sets
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)
data_train <- as.data.frame(c(saratoga_train[1],all_polym2(saratoga_train[2:10]),saratoga_train[11:16]))
data_test <- as.data.frame(c(saratoga_test[1],all_polym2(saratoga_test[2:10]),saratoga_test[11:16]))
#Here lm1 is the medium model as per the lecture notes (taught in class).
lm1 = lm(price ~. -pctCollege -sewer -waterfront -landValue-newConstruction, data=saratoga_train)
lm2 = lm(price ~ lotSize^2 + age^2 + landValue^2 + livingArea^2 + pctCollege^2 + bedrooms^2 + fireplaces^2 + bathrooms^2 + rooms^2 + lotSize:age + landValue:age + livingArea:age + bedrooms:age, data=saratoga_train)
lm3 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:lotSize + landValue:lotSize + livingArea:lotSize + bedrooms:lotSize, data=saratoga_train)
lm4 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:bathrooms + landValue:bathrooms + livingArea:bathrooms + bedrooms:bathrooms, data=saratoga_train)
lm5 = lm(price ~ (. - heating - sewer - waterfront - newConstruction)^2, data=saratoga_train)
## Regression the linear model with all variables
## (because the more variables you will add to the model, the lower rmse you can get)
lm6 = lm(price~ ., data=data_train)
r1[i] = rmse(lm1, saratoga_test)
r2[i] = rmse(lm2, saratoga_test)
r3[i] = rmse(lm3, saratoga_test)
r4[i] = rmse(lm4, saratoga_test)
r5[i] = rmse(lm5, saratoga_test)
r6[i] = rmse(lm6,data_test)
## Regression the Knn model with all variables
### now rescale for KNN with variables else dummies
X_train <- saratoga_train[,2:10]
X_test <- saratoga_test[,2:10]
scale_train = apply(X_train, 2, sd) # calculate std dev for each column
Xtilde_train = scale(X_train, scale = scale_train) %>% as.data.frame
Xtilde_test = scale(X_test, scale = scale_train) %>% as.data.frame # use the training set scales!
Xtilde_train = as.data.frame(cbind(Xtilde_train, saratoga_train['price'],saratoga_train[,11:16]))
Xtilde_test = as.data.frame(cbind(Xtilde_test, saratoga_test['price'],saratoga_test[,11:16]))
maxK=200
## KNN
knnrmse = foreach(K = 2:maxK, .combine='rbind') %do% {
knn = knnreg(price ~ ., data=Xtilde_train, k=K)
c(k=K,rmse=modelr::rmse(knn,Xtilde_test))
}%>% as.data.frame
Knnrmse = as.data.frame(cbind(Knnrmse, knnrmse$rmse))
}
## Compared the result of the linear and knn( knn' rmse selected by the minimum of rmse)
result_lm1 = mean(r1, 1, mean, na.rm=TRUE)
result_lm2 = mean(r2, 1, mean, na.rm=TRUE)
result_lm3 = mean(r3, 1, mean, na.rm=TRUE)
result_lm4 = mean(r4, 1, mean, na.rm=TRUE)
result_lm5 = mean(r5, 1, mean, na.rm=TRUE)
result_lm6 = mean(r6, 1, mean, na.rm=TRUE)
result_knn = as.data.frame(apply(Knnrmse[,1:10], 1, mean, na.rm=TRUE))
result_knn =result_knn[result_knn ==min(result_knn ),]
result = c(result_lm1,result_lm2,result_lm3,result_lm4,result_lm5,result_lm6,result_knn)
#summary(model1)
result
# Setup
data(SaratogaHouses)
Lmrmse =NULL
Knnrmse =NULL
r1= NULL
r2=NULL
r3=NULL
r4 = NULL
r5=NULL
r6=NULL
# Function: Create polym2
## Input: Dataset
## Output: New Dataset
## Create polynominal term by each column
## Example: dataframe(column 1*column1, column 1*column 2, .... column i*column j,....)
all_polym2 <- function (dataset){
result <- dataset
for (i in 1:ncol(dataset)){
for (j in i:ncol(dataset)){
if(j==i){
tmp = as.data.frame(dataset[,j]^2)
colnames(tmp) <- paste(colnames(dataset[j]),"sq")
}else
{
tmp = as.data.frame(dataset[,i] * dataset[,j])
colnames(tmp) <- paste(colnames(dataset[i]),"_",colnames(dataset[j]))
}
result <- as.data.frame(c(result,tmp))
}
}
return(result)
}
# Estimation
for (i in 1:10){
## Split into training and testing sets
saratoga_split = initial_split(SaratogaHouses, prop = 0.8)
saratoga_train = training(saratoga_split)
saratoga_test = testing(saratoga_split)
data_train <- as.data.frame(c(saratoga_train[1],all_polym2(saratoga_train[2:10]),saratoga_train[11:16]))
data_test <- as.data.frame(c(saratoga_test[1],all_polym2(saratoga_test[2:10]),saratoga_test[11:16]))
#Here lm1 is the medium model as per the lecture notes (taught in class).
lm1 = lm(price ~. -pctCollege -sewer -waterfront -landValue-newConstruction, data=saratoga_train)
lm2 = lm(price ~ lotSize^2 + age^2 + landValue^2 + livingArea^2 + pctCollege^2 + bedrooms^2 + fireplaces^2 + bathrooms^2 + rooms^2 + lotSize:age + landValue:age + livingArea:age + bedrooms:age, data=saratoga_train)
lm3 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:lotSize + landValue:lotSize + livingArea:lotSize + bedrooms:lotSize, data=saratoga_train)
lm4 = lm(price ~ lotSize + age + landValue + livingArea + pctCollege + bedrooms + fireplaces + bathrooms + rooms + age:bathrooms + landValue:bathrooms + livingArea:bathrooms + bedrooms:bathrooms, data=saratoga_train)
lm5 = lm(price ~ (. - heating - sewer - waterfront - newConstruction)^2, data=saratoga_train)
## Regression the linear model with all variables
## (because the more variables you will add to the model, the lower rmse you can get)
lm6 = lm(price~ ., data=data_train)
r1[i] = rmse(lm1, saratoga_test)
r2[i] = rmse(lm2, saratoga_test)
r3[i] = rmse(lm3, saratoga_test)
r4[i] = rmse(lm4, saratoga_test)
r5[i] = rmse(lm5, saratoga_test)
r6[i] = rmse(lm6,data_test)
## Regression the Knn model with all variables
### now rescale for KNN with variables else dummies
X_train <- saratoga_train[,2:10]
X_test <- saratoga_test[,2:10]
scale_train = apply(X_train, 2, sd) # calculate std dev for each column
Xtilde_train = scale(X_train, scale = scale_train) %>% as.data.frame
Xtilde_test = scale(X_test, scale = scale_train) %>% as.data.frame # use the training set scales!
Xtilde_train = as.data.frame(cbind(Xtilde_train, saratoga_train['price'],saratoga_train[,11:16]))
Xtilde_test = as.data.frame(cbind(Xtilde_test, saratoga_test['price'],saratoga_test[,11:16]))
maxK=200
## KNN
knnrmse = foreach(K = 2:maxK, .combine='rbind') %do% {
knn = knnreg(price ~ ., data=Xtilde_train, k=K)
c(k=K,rmse=modelr::rmse(knn,Xtilde_test))
}%>% as.data.frame
Knnrmse = as.data.frame(cbind(Knnrmse, knnrmse$rmse))
}
## Compared the result of the linear and knn( knn' rmse selected by the minimum of rmse)
result_lm1 = mean(r1, 1, mean, na.rm=TRUE)
result_lm2 = mean(r2, 1, mean, na.rm=TRUE)
result_lm3 = mean(r3, 1, mean, na.rm=TRUE)
result_lm4 = mean(r4, 1, mean, na.rm=TRUE)
result_lm5 = mean(r5, 1, mean, na.rm=TRUE)
result_lm6 = mean(r6, 1, mean, na.rm=TRUE)
result_knn = as.data.frame(apply(Knnrmse[,1:10], 1, mean, na.rm=TRUE))
result_knn =result_knn[result_knn ==min(result_knn ),]
result = c(result_lm1,result_lm2,result_lm3,result_lm4,result_lm5,result_lm6,result_knn)
#summary(model1)
result
result_knn
save.image("C:/Users/hasimoto/Desktop/test.RData")
